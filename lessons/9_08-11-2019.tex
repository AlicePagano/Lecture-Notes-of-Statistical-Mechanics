\documentclass[../main/main.tex]{subfiles}

\newdate{date}{8}{11}{2019}


\begin{document}

\marginpar{ \textbf{Lecture 9.} \\  \displaydate{date}. \\ Compiled:  \today.}

In this denaturation transition we do not allow bubbles. In principle, we have a zipper model by open one side:
Fig 1
This is the single zipper.
The \( \varepsilon _0 \) is the energy to open the \( k+1 \) side.
One the bound it is open, then it could assume the \emph{G}, number of possible orientations of open bonds. There is a sort of entropy associated to this bond open (for each open bound):
 \begin{equation}
   S_0 = k_B \log{G}
 \end{equation}
Even there are \emph{k} bonds open, the energy that you get when you open is:
\begin{equation}
  G^k e^{-k \varepsilon _0/k_B T}
\end{equation}
this is the boltzmann factor. We have the partition function as the sum over all configurations:
\begin{equation}
  Z_N (T,G, \varepsilon _0) = \sum_{k=0}^{N-1}  G^k e^{-k \varepsilon _0/k_B T}
\end{equation}
We can rewrite by using the definition of entropy:
\begin{equation}
  \Rightarrow Z_N = \sum_{k=0}^{N-1} e^{k(S_0 T - \varepsilon _0)/k_B T}
\end{equation}
Just to simplify notation we define \( \chi \equiv G e^{-\varepsilon _0/k_B T}  \) :
\begin{equation}
  Z_N = \sum_{k=0}^{N-1} \chi ^k = \frac{1-x^N}{1-x}
\end{equation}
we see immidiately there is a single pole singularity.
So for example the free energy is
\begin{equation}
  F_N = -k_B T \ln{Z_N} = -k_B T \ln{\qty[\frac{1-x^N}{1-x}]}
\end{equation}
The equal of our magnetization in this case is
\begin{equation}
  \expval{k}_N = \frac{\sum_{k=0}^{N-1} k x^k}{\sum_{k=0}^{N-1} x^k } = x \dv[]{}{x} \ln{Z_N}  = \frac{N x^N}{x^N-1} - \frac{x}{x-1}=
\end{equation}
The derivative of this generating function will give you the moments of the parameter...
The last quantity can be drawn as in Figure 3. In order to analyze what happens near 1, we expand \( x=1+\varepsilon  \):
\begin{equation}
  \log{Z_N} = \log{\qty[\frac{1-(1+\varepsilon )^N}{1-(1+\varepsilon )}] } =
  \log{\qty[\frac{1-(1+\varepsilon N  + \frac{N(N+1)}{2!}\varepsilon ^2 + \frac{N(N-1)(N-2)}{3!}\varepsilon ^3 +O(\varepsilon ^4))}{\varepsilon }] }
\end{equation}
\begin{equation}
  = \log{\qty[N + \frac{N(N-1)}{2}\varepsilon + \frac{N(N-1)(N-2)}{6}\varepsilon^2]  }
  = \log{N} + \log{\qty[1+\frac{N-1}{2}\varepsilon +\frac{(N-1)(N-2)}{6}\varepsilon ^2] }
\end{equation}
\begin{equation}
  = \log{N} + \qty( \frac{N \varepsilon }{2} + \frac{N^2 \varepsilon ^2}{6} + \dots) + \frac{1}{2} \qty(\frac{N \varepsilon }{2} + \frac{N^2 \varepsilon ^2}{6} + \dots)^2  + \dots
\end{equation}
\begin{equation}
  \log{Z_N} \simeq \log{N} + \frac{N \varepsilon }{2} + \frac{N^2 \varepsilon ^2}{24} + \dots \Rightarrow \expval{k}_N = \frac{N}{2} \qty( 1 + \frac{N \varepsilon }{6} - \frac{N^2 \varepsilon ^2}{30} + \dots)
\end{equation}
The result is
\begin{equation}
  \expval{k}_N \simeq \frac{N}{2}
\end{equation}
You can define the variation as a response function (the derivative with respect to the parameter)
\begin{equation}
  \frac{1}{N}\dv{\expval{k} }{\varepsilon } = \frac{N}{12} - \frac{N^3 \varepsilon ^3}{240}
\end{equation}
The response function diverges linearly to \emph{N}. This is a good signal that we have a transition. The critical transition is at the point \( x_c = 1 \), what we obtain in this point is:
\begin{equation}
  1 = G e^{-\varepsilon _0 /k_B T_C} \Rightarrow T_C = \frac{\varepsilon _0}{k_B \log{G} }
\end{equation}
we find a transition, it is a one dimensional model. This is telling you that if \( G=1 \) what is important it is the energy, you have no entropy as disorder.
At that point everything can happen.

The idea is: we want to map this model to an Ising model.
The tipical configuration is as in Figure 4, where \( S_i = 0 \) if the \emph{i}-esim bond is closed, if the \emph{i}-esim bond is open we have \( S_i = 1, \dots, G \).
If \( S_i = 0 \), we have the case \( S_{i-1} = 0 \)  with energy \( V_0 \) or the case  \( S_{i-1} \neq 0 \)  with energy \( \varepsilon _0 \).
\begin{equation}
  E ( S_i, S_{i-1}) = ( \varepsilon _0 + \cancel{ V_0} \delta _{S_{i-1},0}) (1- \delta _{S_i,0})
\end{equation}
In the kittel model the \( V_0 \) is zero (??).
We can write an Hamiltonian that could be also a function of delta, but it is not a problem:
\begin{equation}
  \mathcal{H} (S_i, S_{i-1})
\end{equation}

\section{2D Ising model}
Dimensional reducation from \emph{d} to \emph{d-1}. You can to the same for the 3D Ising model. In order to go smoothly to the one dimensional to the two dimensional the idea is to solve the Ising model to surfaces.

Consider a square lattice, each location can be described by \( (n,m) \), therefore the spins in that position is \( S_{m,n} \). We use periodic boundary condition.
\begin{equation}
  \sum_{\expval{i,j} }^{}  \rightarrow \sum_{i,j \in nn(i)}^{}
\end{equation}
therefore,
\begin{equation}
  S_{m,n} \rightarrow S_{m+1,n}
\end{equation}
What we have is
\begin{equation}
  -\beta \mathcal{H} ( \{ S \}  ) = k \sum_{n=1}^{N} \sum_{m=1}^{M} (S_{m,n} S_{m+1,n}+S_{m,n}S_{m,n+1})
\end{equation}
If \( H \neq 0 \) we have also the term:
\begin{equation}
  + h\sum_{m=1}^{M} \sum_{n=1}^{N} S_{m,n}
\end{equation}
In this way we try to figure out why it is okay:
\begin{equation}
  -\beta \mathcal{H} ( \{ S \}  ) = \sum_{m=1}^{M} \qty[E[\mu _m, \mu _{m+1}] + E[\mu _m]]
\end{equation}
where the \( \mu  \)  is a \emph{m} dimensional vector. The first term is the interaction between columns (two body interaction), the second term is the one body interaction of one column. First of all, write:
\begin{equation}
  \mu _m = \{ S_{m,1}, S_{m,2}, \dots, S_{m,N} \}
  \label{eq:9_1}
\end{equation}
We have:
\begin{equation}
  E [ \mu _m,h] = k \sum_{n=1}^{N} S_{m,n} S_{m,n+1} + h \sum_{n}^{} S_{m,n}
\end{equation}
in the quantum version there will be an hilbert space that is consituted by the product of the colums.
We have also:
\begin{equation}
  E [\mu _m, \mu _{m+1},h] = k \sum_{n=1}^{N} S_{m,n} S_{m+1,n}
\end{equation}
I can write a transfer matrix between these new variables. The transfer matrix permit to transfer along the \emph{m}. To make it simpler suppoe \( h=0 \) (so the energy does not depend on h):
\begin{equation}
  \bra{\mu _m} \mathbb{T} \ket{\mu _{m+1}} = \exp [ E [\mu _m, \mu _{m+1}] + E [ \mu _m]]
\end{equation}
Now we have to diagonalize. In the 2x2 tranfer matrix in the two dimensional we have 2 possible values. Now we have to do the same in principle, but we have to do for all of the \eqref{eq:9_1}.
\( dim(\mathbb{T}) = 2^N \times 2^N \)
\begin{equation}
  Z_{NM} (k,h) = \Tr(\mathbb{T}^M)
\end{equation}
the big problem it is that in the thermodynamic limit is that the dimension of the transfer matrix goes to infinity, then it is diffucult to be diagonalized.
The density bulk free energy is something like
\begin{equation}
  f_b (T) = -k_B T \log{\qty(2 \cosh(2 \beta J))- \frac{k_B T}{2 \pi} \int_{0}^{2\pi} \log{\qty[\frac{1}{2}\qty(1+ \sqrt{1-g^2 \sin^2(\Phi) } )] } \dd[]{\Phi }  }
\end{equation}
we have
\begin{equation}
  g = \frac{2}{\cosh(2 \beta J)\coth(2 \beta J)}
\end{equation}
\begin{equation}
  2 \tanh^2 \qty(\frac{2J}{k_B T_c}) = 1 \Rightarrow T_c \simeq 2,264 J/k_B \neq 0
\end{equation}
The specific heat:
\begin{equation}
  c \propto A \qty[-\ln{\qty(1- \frac{T}{T_c}) } + B  ]
\end{equation}
the divergence there is, but it is logarithmic. It means that in \( d=2 \)  the Ising model as \( \alpha =0 \). You do Montecarlo simulation.    












\end{document}
