\documentclass[../main/main.tex]{subfiles}

\newdate{date}{20}{11}{2019}


\begin{document}

\marginpar{ \textbf{Lecture 11.} \\  \displaydate{date}. \\ Compiled:  \today.}

The Hamiltonian is:
\begin{equation}
  - \mathcal{H} ( \{ S \}  ) = \frac{J}{2N} \sum_{ij}^{} S_i S_j + H \sum_{i}^{} S_i
\end{equation}
where the second term is associated to an external magnetic field. We have a function:
\begin{equation}
Z_N (T,J,H) = \sum_{\{ S \}  }^{} \exp [\frac{\beta J}{2N} \sum_{ij}^{} S_i S_j + \beta H \sum_{i}^{} S_i    ]
\end{equation}
where the term \( \sum_{ij}^{} S_i S_j  = \qty( \sum_{i}^{} S_i )^2 \). Rerite the partition function:
\begin{equation}
  Z_N (T,J,H)  =   \sum_{\{ S \}  }^{} \exp  [\frac{K}{2N} \qty( \sum_{i}^{} S_i )^2 + h \sum_{i}^{} S_i    ]
\end{equation}
This is the Hubbard-stratonovitch transformation (you can do it in any dimension). The idea is to rewrite something as a square. Let us define:
\begin{equation}
  x \equiv \sum_{i}^{} S_i
\end{equation}
The identity is the following
\begin{equation}
  e^{\frac{K x^2}{2N}} =  \sqrt{\frac{N K}{2 \pi }} \int_{-\infty }^{+\infty } e^{-\frac{N K}{2}y^2+Kxy} \dd[]{y}
\end{equation}
The real part of \emph{K} \( \Re(K) >0  \). y is a random field that follows a random distribution. We want to do:
\begin{proof}
  \begin{equation}
    - \frac{N K}{2} y^2 + K x y = - \frac{N K}{2} \qty(y - \frac{x}{N})^2 + \frac{K x^2}{2N}
  \end{equation}
  Then we integrate:
  \begin{equation}
    e^{\frac{K x^2}{2N}} \int_{- \infty }^{+ \infty } e^{- \frac{N K}{2} \qty(y - \frac{x}{N})^2 } \dd[]{y}
  \end{equation}
  if \( z \equiv y - \frac{x}{N} \) , \( \dd[]{z} = \dd[]{y}   \) :
  \begin{equation}
    \rightarrow \int_{-\infty }^{+\infty } e^{- \alpha z^2} \dd[]{z} = \sqrt{\frac{\pi }{\alpha }}
  \end{equation}
  with \( \alpha \equiv \frac{N K}{2} \), therefore
  \begin{equation}
    = e^{\frac{K x^2}{2N}} \sqrt{\frac{2 \pi }{N K}}
  \end{equation}
\end{proof}
We have:
\begin{equation}
  Z_N = \sqrt{\frac{N K}{2 \pi }} \int_{-\infty }^{+ \infty } \dd[]{y} e^{- \frac{NK}{2}y^2} \underbrace{\qty[\sum_{\{ S \}  }^{}  e^{(h+Ky) \sum_{i}^{} S_i  }  ]}_{Q_y}
\end{equation}
Sometimes the \emph{y} is called \emph{auxiliary field}.
\begin{equation}
  Q_y = \prod_{i}^{N} \qty(\sum_{S_i = \pm 1}^{} \exp [ (h+Ky) S_i]  )  = \qty( 2 \cosh (h+Ky))^N
\end{equation}
it becomes:
\begin{equation}
  = \sqrt{\frac{N K}{2 \pi }} \int_{- \infty }^{+ \infty } \dd[]{y} e^{- \frac{NK}{2}y^2} \qty(2 \cosh(h+Ky))^N = \sqrt{\frac{N K}{2 \pi }} \int_{-\infty }^{+\infty } \dd[]{y} e^{N \alpha (K,h,y)}
\end{equation}
where
\begin{equation}
  \alpha (K,h,y) = \ln{\qty[2 \cosh(h+Ky)] } - \frac{K}{2}y^2
\end{equation}
Maybe we can replace the medium of the integral with the maximum of the integrand, we say that all the information is coming only from a bit of information. Replace the all integral with the integrand computed where it is maximum. That is an approximation and we are loosing information, it depends on the form of the function. For example, for a delta function it works better. This is the Saddle point approximation. In general:
\begin{equation}
  \int_{-\infty }^{+ \infty } f(x) \dd[]{y} \rightarrow f(\bar{x} )
\end{equation}
where \( \bar{x} = \max_{x} f(x)  \)
\begin{equation}
  Z_N \approx \sqrt{\frac{N K}{2 \pi }} \max_y \qty[\exp [N \alpha ] ]
\end{equation}
We call \( y_s \) be the value of \( y \) at which \( \alpha (K,h,y_s) = \max_y \alpha  \).
Therefore:
\begin{equation}
  \Rightarrow Z_N^S (K,h) \sim \sqrt{\frac{N K}{2 \pi }} e^{N \alpha (K,h,y_s)}
\end{equation}
Therefore when we are ample to compute the \( y_s \) we can do this approximation.
\begin{equation}
  f_b = \lim_{N \rightarrow \infty } \frac{1}{N} \qty(- k_B T \log{Z_N}) = -k_B T \alpha (h,K,y_s)
\end{equation}
Consider the condition \( \pdv{\alpha }{y} = 0  \):
\begin{equation}
  \pdv{\alpha }{y} = \frac{\sinh (h+Ky)K}{\cosh (h+Ky)} - Ky = 0
\end{equation}
\begin{equation}
  \Rightarrow y_s = \tanh (h+Ky_s)
\end{equation}

The magnetization is
\begin{equation}
  m = - \pdv{f}{H} \underset{\text{to do!}}{=}  \pdv{\alpha }{h}  + \frac{O ( \log{N} )}{N}
  = \tanh (K y_s +h)
\end{equation}
So at the end
\begin{equation}
  m = \tanh (h+Km)
\end{equation}
this will give us the equilibrium value of \emph{m}! We have solved analitically this one.


The most important approximation is the \emph{mean field approximation}. Try to simplify the problem by negletic the correlation between the fluctuations.
\begin{equation}
  Z_N = \sum_{\{ S \}  }^{} e^{\beta \qty[\frac{1}{2} \sum_{\expval{ij} }^{} J_{ij} S_i S_j + \sum_{i}^{} H_i S_i   ] }
\end{equation}
The magnetization per spin is \( m \equiv \expval{S_i}  \). Let us consider \( H_i = H \) uniform. The simplest approximation is:
we have our nasty term, let us rewrite it in this way
\begin{equation}
  S_i S_j = (S_i - m + m) (S_j - m + m) = \underbrace{(S_i - m ) (S_j - m)}_{S_i - \expval{S_i} }  + m^2 + m (S_j-m) + m (S_i-m)
\end{equation}
where \( S_i - \expval{S_i}  \) are the fluctuations, so the mean field neglets correlations of the fluctuations:

\begin{equation}
  S_i S_j = (S_i - m + m) (S_j - m + m) = \cancel{ (S_i - m ) (S_j - m) }  + m^2 + m (S_j-m) + m (S_i-m)
\end{equation}
\begin{equation}
  \Rightarrow \approx m^2 + m(S_i-m) + m(S_j-m)
\end{equation}
We have:
\begin{equation}
  \frac{1}{2} \sum_{\expval{ij} }^{} S_i S_j \overset{MF}{\approx } \frac{1}{2} \sum_{\expval{ij} }^{} J_{ij} \qty[-m^2+m(S_i+S_j)]
\end{equation}
\begin{equation}
  \frac{1}{2} \sum_{\expval{ij} }^{} J_{ij} m(S_i+S_j) = \frac{2}{2} \sum_{\expval{ij} }^{} J_{ij} m S_i
  \label{eq:11_1}
\end{equation}
Let us write in this way: (n.n. = neirest neighbour)
\begin{equation}
  \sum_{j \text{ n.n. of } i}^{} J_{ij} = z \hat{J}_i \simeq  z \hat{J}
\end{equation}
Therefore \eqref{eq:11_1} became
\begin{equation}
  = m \hat{J} z \sum_{i}^{} S_i
\end{equation}
If you do the same story over j for the sum over i:
\begin{equation}
  Z_N \approx e^{-\frac{\beta m^2 N}{2} z \hat{J} } \sum_{\{ S \}  }^{}  e^{\beta (\hat{J}zm + H ) \sum_{i}^{} S_i }
\end{equation}
\begin{equation}
  \approx e^{-\frac{\beta m^2 N}{2} z \hat{J} } \qty(2 \cosh [\beta (\hat{J}zm+H )])^N
\end{equation}
The free energy mean field is:
\begin{equation}
  f_b^{MF} = - \frac{1}{N}k_B T \log{Z_N} = \frac{1}{2}\hat{J} z m^2 -k_B T \log{[2\cosh(\beta (\hat{J} z m + H))]} - k_B T \ln{2}
\end{equation}
We are replacing the interaction of the J with a field close to the \( S_i \). We called \( \hat{J} z m = H_{eff}  \), the mean field!

Self consistency  must satisfy the thermodynamic relation:
\begin{equation}
  m = - \qty( \pdv{f}{H})_T
\end{equation}
this is the \emph{self-consistent constraint}. The self consistent relation is therefore:
\begin{equation}
  m = \tanh (\beta (\hat{J}z m + H  ))
\end{equation}
The iperbolic function (insert Figure in cellulare (copiare da qualcuno)). \( H=0 \). For the value of the parameter \( \beta \hat{J} z > 1  \), we find solution \( m_0 \neq 0 \).  Two solution are symmetric because they are related by the z symmetry.

If we look for the csase \( \beta \hat{J} z < 1  \), we have just one solution that is equal to zero \( m_0 = 0 \).

The condition \( \beta_c \hat{J} z = 1  \), define the critical point
\begin{equation}
  \frac{z \hat{J} }{k_B T_c} = 1 \Rightarrow T_c = \frac{z \hat{J} }{k_B} \neq 0
\end{equation}

The critical point is characterized by the order parameter that is zero. Now we want to expand the free energy around the critical point. Let us put \( H=0 \).
\begin{equation}
  \cosh (x) = 1 + \underbrace{\frac{x^2}{2} + \frac{x^4}{4!}}_{t}  + \dots
\end{equation}
\begin{equation}
  \log{(1+t)}
\end{equation}
\begin{equation}
  f(m,T) = cost + \frac{A}{2} m^2 + \frac{B}{4} m^4 + O (m^6)
\end{equation}
\begin{equation}
  A = \hat{J} z \qty(1- \beta \hat{J} z)
\end{equation}
\begin{equation}
  B = \beta ^2 \frac{(\hat{J}z )^4}{3} > 0
\end{equation}

Figure in cellulare 2. 





\end{document}
