\documentclass[../main/main.tex]{subfiles}

\newdate{date}{20}{11}{2019}


\begin{document}

\marginpar{ \textbf{Lecture 11.} \\  \displaydate{date}. \\ Compiled:  \today.}

The partition function is

\begin{equation}
Z_N (T,J,H) = \sum_{\{ S \}  }^{} \exp [\frac{\beta J}{2N} \sum_{ij}^{} S_i S_j + \beta H \sum_{i}^{} S_i    ]
\end{equation}
Since there are no restrictions on the double sum we can write
\begin{equation}
  \sum_{ij}^{} S_i S_j  = \qty(\sum_{i}^{} S_i ) \qty(\sum_{j}^{} S_j )= \qty( \sum_{i}^{} S_i )^2
\end{equation}
Rewriting the partition function:
\begin{equation}
  Z_N (T,J,H)  =   \sum_{\{ S \}  }^{} \exp  [\frac{K}{2N} \qty( \sum_{i}^{} S_i )^2 + h \sum_{i}^{} S_i    ]
\end{equation}
In order to transform the quadratic term into al inear one we make use of the integral identity known as the \emph{Hubbard-stratonovitch transformation} (we can do it in any dimension). The idea is to rewrite something as a square.

Let us define:
\begin{equation}
 x \equiv \sum_{i}^{} S_i
\end{equation}
The following identity holds
\begin{equation}
  e^{\frac{K x^2}{2N}} =  \sqrt{\frac{N K}{2 \pi }} \int_{-\infty }^{+\infty } e^{-\frac{N K}{2}y^2+Kxy} \dd[]{y}, \quad \text{with} \quad \Re(K) >0
  \label{eq:11_1}
\end{equation}
where \emph{y} is a random field that follows a random distribution.
To show the identity above it is sufficient to complete the square
\begin{proof}(of \eqref{eq:11_1})
  \begin{equation}
    - \frac{N K}{2} y^2 + K x y = - \frac{N K}{2} \qty(y - \frac{x}{N})^2 + \frac{K x^2}{2N}
  \end{equation}
  Then we integrate:
  \begin{equation}
    e^{\frac{K x^2}{2N}} \int_{- \infty }^{+ \infty } e^{- \frac{N K}{2} \qty(y - \frac{x}{N})^2 } \dd[]{y} \overset{(a)}{=}  e^{\frac{K x^2}{2N}} \sqrt{\frac{2 \pi }{N K}}
  \end{equation}
  where in \( (a) \) we have considered \( z \equiv \qty( y - \frac{x}{N} )\) , \( \dd[]{z} = \dd[]{y}   \):
  \begin{equation}
    \rightarrow \int_{-\infty }^{+\infty } e^{- \alpha z^2} \dd[]{z} = \sqrt{\frac{\pi }{\alpha }}
  \end{equation}
  with \( \alpha \equiv \frac{N K}{2} \).
\end{proof}
By using \eqref{eq:11_1} we have
\begin{equation}
  Z_N (K,h)= \sqrt{\frac{N K}{2 \pi }} \int_{-\infty }^{+ \infty } \dd[]{y} e^{- \frac{NK}{2}y^2} \underbrace{\qty[\sum_{\{ S \}  }^{}  e^{(h+Ky) \sum_{i}^{} S_i  }  ]}_{Q_y}
\end{equation}
Sometimes \emph{y} is called \emph{auxiliary field}. If \emph{y} is a fluctuating external field  with Gaussian distribution
\begin{equation}
\begin{split}
 Q_y  =  \sum_{\{ S \}  }^{}  e^{(h+Ky) \sum_{i}^{} S_i  }
      &= \prod_{i}^{N} \qty(\sum_{S_i = \pm 1}^{} \exp [ (h+Ky) S_i]  )\\
      &= \qty( 2 \cosh (h+Ky))^N
\end{split}
\end{equation}
The partition function becomes
\begin{equation}
Z_N (K,h) = \sqrt{\frac{N K}{2 \pi }} \int_{- \infty }^{+ \infty } \dd[]{y} e^{- \frac{NK}{2}y^2} \qty(2 \cosh(h+Ky))^N = \sqrt{\frac{N K}{2 \pi }} \int_{-\infty }^{+\infty } \dd[]{y} e^{N \alpha (K,h,y)}
\end{equation}
where
\begin{equation}
  \alpha (K,h,y) = \ln{\qty[2 \cosh(h+Ky)] } - \frac{K}{2}y^2
\end{equation}

\begin{remark}
In the limit \( N \rightarrow \infty  \) the integral can be computed exactly by the \emph{saddle point method}.
We can replace the medium of the integral with the maximum of the integrand, we say that all the information is coming only from a bit of information. Replace the all integral with the integrand computed where it is maximum. That is an approximation and we are loosing information, it depends on the form of the function. For example, for a delta function it works better. In general:
\begin{equation}
  \int_{-\infty }^{+ \infty } f(x) \dd[]{y} \rightarrow f(\bar{x} )
\end{equation}
where \( \bar{x} = \max_{x} f(x)  \).
\end{remark}


Indeed as \( N \rightarrow \infty  \), since the integrand is \( \exp (N \alpha (K,h,y))  \), the integral is dominated by the global maximum in \emph{y} of the function \( \alpha (K,h,y) \).
\begin{equation}
  Z_N (K,h) \overset{N \gg1 }{\approx}  \sqrt{\frac{N K}{2 \pi }} \max_y \qty[e ^{N \alpha(K,h,y) } ]
\end{equation}
Let \( y_s \) be the value of \( y \) at which
\begin{equation}
  \alpha (K,h,y_s) = \max_y \alpha (K,h,y)
\end{equation}
therefore
\begin{equation}
  Z_N (K,h) \overset{N \gg1 }{\approx} \sqrt{\frac{N K}{2 \pi }} e^{N \alpha (K,h,y_s)}
\end{equation}
When we are ample to compute the \( y_s \) we can do this approximation and
\begin{equation}
  f_b (K,h)= \lim_{N \rightarrow \infty } \frac{1}{N} \qty(- k_B T \log{Z_N}) = -k_B T \alpha (K,h,y_s)
\end{equation}
Looking for \( y_s \) we consider the condition \( \pdv{\alpha }{y} = 0  \):
\begin{equation}
  \pdv{\alpha }{y} = \frac{\sinh (h+Ky)K}{\cosh (h+Ky)} - Ky = 0 \quad   \Rightarrow y_s = \tanh (h+Ky_s)
\end{equation}
The last one is an implicit equation that can be solved graphically as a function of \emph{K} and \emph{h}.

The magnetization in the \( N \rightarrow \infty  \) limit is given by
\begin{equation}
\begin{split}
m  &= - \qty( \pdv{f}{H})_T = \lim_{N \rightarrow \infty } \frac{1}{\beta N} \pdv{\ln{Z_N(K,h)} }{H}   \\
& =  \pdv{\alpha (K,h,y_s) }{h}  + \frac{O ( \log{N} )}{N} = \frac{2 \sinh(Ky_s+h)}{2 \cosh(ky_s+h)} \\
& = \tanh (K y_s +h)
\end{split}
\end{equation}
At the end \( m \equiv y_s \)
\begin{equation}
  m = \tanh (h+Km)
\end{equation}
that is a self consistent equation. We have solved analitically this problem.


\chapter{Mean field theories of phase transitions and variational mean field}

\section{Mean field theories}

Increasing the dimension of the systems the effort to solve analitically the problems increase , in fact we have seen that
\begin{itemize}
\item In \( D=1 \): many (simple) models can be solved exactly using techniques such as the transfer matrix method.
\item In \( D=2 \): few models can still be solved exactly (often with a lot of effort).
\item In \( D=3 \): almost no model can be exactly solved.
\end{itemize}
hence, approximations are needed.
The most important and most used one is the \emph{mean field approximation}. The idea is to try to simplify the problem by negletic the correlation between the fluctuations of the order parameter. It is equivalent to a statistical indipendence of the microscopic degrees of freedom.

The mean field approximation has different names depending on the system considered:
\begin{itemize}
\item Magnetic: Weiss theory.
\item Fluids: Van der Walls.
\item Polymers: Flory's theory.
\end{itemize}

\subsection{Mean field for Ising model}
Let us start from the following generic model
\begin{equation}
  \mathcal{H} [\{ S \}  ] =  -\frac{1}{2} \sum_{ij}^{} J_{ij} S_i S_j - H \sum_{i}^{} S_i
\end{equation}
where the double sum over \( i \) and \( j \) have no restrictions, while \( H \) is homogeneous.
\begin{equation}
  Z_N (T,H,\{ J_{ij} \}  )= \sum_{\{ S \}  }^{} e^{-\beta   \mathcal{H} [\{ S \}] } = \exp (-\beta F_N (T,H,\{ J_{ij} \}  ))
\end{equation}
Since \( H \) is uniform, the magnetization per spin is
\begin{equation}
  \expval{S_i}  = \expval{S} \equiv m
\end{equation}
Let us now consider the idenity
\begin{equation}
\begin{split}
  S_i S_j  &= (S_i - m + m) (S_j - m + m)  \\
  & = (S_i - m ) (S_j - m)  + m^2 + m (S_j-m) + m (S_i-m)
\end{split}
\end{equation}
\begin{remark}
The term
\begin{equation*}
  (S_i - m ) (S_j - m) = (S_i - \expval{S_i})(S_j - \expval{S_j})
\end{equation*}
measures correlation between fluctuations. The mean field approximation consists in neglecting this term!
\end{remark}
Using the mean field approximation,
\begin{equation}
  S_i S_j  \approx m^2 + m(S_i-m) + m(S_j-m)
\end{equation}
we obtain
\begin{equation}
  \frac{1}{2} \sum_{i,j}^{} J_{ij}S_i S_j \overset{MF}{\approx } \frac{1}{2} \sum_{i,j }^{} J_{ij} \qty[-m^2+m(S_i+S_j)]
\end{equation}
Let us focus on the term
\begin{equation}
  \frac{1}{2} \sum_{i,j }^{} J_{ij} m (S_i+S_j) = 2 \frac{1}{2} m \sum_{i,j }^{} J_{ij}  S_i
  \label{eq:11_2}
\end{equation}
If we do not many assumption on \( J_{ij} \) the mean field hamiltonian is
\begin{equation}
\mathcal{H}_{MF} [ \{ S \}  ] = \frac{1}{2} m^2 \sum_{ij}^{} J_{ij} - m \sum_{ij}^{} J_{ij} S_i - H \sum_{i}^{} S_i
\end{equation}
and by calling
\begin{equation}
  \bar{J_i} \equiv  \sum_{j}^{} J_{ij}
\end{equation}
we get
\begin{equation}
    \mathcal{H}_{MF} [ \{ S \}  ]  = \frac{1}{2} m^2 \sum_{i}^{} \bar{J_i} - \mathcolorbox{green!20}{\frac{m}{2}} \sum_{i}^{} \bar{J_i} S_i - H \sum_{i}^{} S_i
\end{equation}
\begin{remark}
Note the coefficient \( 1/2 \) that is needed to avoid the double counting of bonds.
\end{remark}
If moreover we suppose that
\begin{equation*}
  \bar{J_i} \rightarrow \bar{J}
\end{equation*}
we have
\begin{equation}
  \mathcal{H}_{MF} [ \{ S \}  ] = \frac{1}{2} m^2 N \bar{J} - \qty(\frac{m}{2}\bar{J} +H) \sum_{i}^{} S_i
\end{equation}
In the standard Ising model, where
\begin{equation}
  \frac{1}{2} \sum_{ij}^{} J_{ij} S_i S_j \rightarrow \sum_{\expval{ij} }^{} J_{ij}    S_i S_j
\end{equation}
the term \( 2 m \sum_{\expval{ij} }^{}  J_{ij} S_i \) can be written as follows;
let
\begin{equation}
  \sum_{j \in n.n.\text{ of } i}^{} J_{ij} = z \hat{J}_i
\end{equation}
where \( z \) is the coordination number of the underlying lattice.
\begin{remark}
For the hypercubic lattice \( z=2D \).
\end{remark}
By assuming \( \hat{J}_i = \hat{J}  \) and inserting the \( 1/2 \) to avoid double counting, we have that equation \eqref{eq:11_2} becames
\begin{equation}
  2m \sum_{\expval{ij} }^{}  J_{ij} S_i = 2 m \frac{1}{2} z \hat{J} \sum_{i=1}^{N} S_i
\end{equation}
Hence,
\begin{equation}
  \mathcal{H}_{MF} [ \{ S \}  ] = \frac{1}{2} m^2 N z \hat{J} - (m z \hat{J} + H ) \sum_{i=1}^{N} S_i
\end{equation}
\begin{equation}
\begin{split}
  Z_N (T,H,\hat{J} ) &= e^{-N \beta \hat{J} \frac{z}{2} m^2 }  \sum_{\{ S \}  }^{} e^{\beta m (\hat{J}zm+H )\sum_{i}^{} S_i }   \\
  & = e^{-N \beta \hat{J} \frac{z}{2} m^2 } \qty(\sum_{S = \pm 1}^{} \exp (\beta ^m \qty(\hat{J}zm+H ) )   )^N \\
  & = e^{-N \beta \hat{J} \frac{z}{2} m^2 } \qty(2 \cosh \qty[\beta \qty(\hat{J}zm+J ) ] )^N
\end{split}
\end{equation}
\begin{remark}
We are replacing the interaction of the J with a field close to the \( S_i \). We called \( \hat{J} z m = H_{eff}  \), the mean field!
\end{remark}

The free energy per spin is
\begin{equation}
\begin{split}
  \frac{F_N (T,H,\hat{J} )}{N} & = \frac{1}{N} \qty(-k_B T \ln{Z_N(T,H,\hat{J} )} ) \\
  & = \frac{1}{2} \hat{J} z m^2 - k_B T \ln{\qty[\cosh(\beta (\hat{J}zm+H ))] } - k_B T \ln{2}
\end{split}
\end{equation}
Sometimes it is useful to use the \emph{dimensionless variables}
\begin{equation}
  \bar{f} \equiv \frac{F_N}{N z \hat{J} }, \quad \theta \equiv \frac{k_B T}{z \hat{J} }, \quad \bar{H} \equiv \frac{H}{z \hat{J} }
\end{equation}
Hence,
\begin{equation}
  \bar{f} (m, \bar{H}, \theta  ) = \frac{1}{2}m^2 - \theta \ln{\qty(2 \cosh (\theta ^{-1}(m+\bar{H} ))) }
\end{equation}

In order to be a self-consistent, the last equation has to satisfy the  thermodynamic relation:
\begin{equation}
  m = - \qty( \pdv{f}{H})_T \quad \Rightarrow   m = \tanh (\beta (\hat{J}z m + H  ))
\end{equation}
\begin{remark}
The results of \( m \)  is similar to the Ising with infinite range (\( \hat{J}z \leftrightarrow J  \)).
\end{remark}
Now, let us consider the \( H=0 \) case, we have
\begin{equation}
  m =  \tanh (\beta (\hat{J}z m ))
\end{equation}
and the graphical solution is shown in Figure \ref{fig:11_1} (hyperbolic function).


\begin{figure}[h!]
\centering
\includegraphics[width=0.9\textwidth]{../lessons/11_image/1.pdf}
\caption{\label{fig:11_1}}
\end{figure}

In particular:
\begin{itemize}
\item case \( \beta \hat{J} z > 1  \): there are three solutions, one at \( m=0 \) and two symmetric at \( m=\pm m_0 \). Magnetization is \( \neq 0 \, (= \abs{m_0} )\) for \( H=0 \) (\emph{ordered phase}).  The two solution are symmetric because they are related by the \( \mathbb{Z}^2 \)  symmetry;
\item case \( \beta \hat{J} z < 1  \): single solution at \( m=0 \) (\emph{disordered or paramagnetic phase});
\item case \( \beta \hat{J} z = 1  \): the three solutions coincide at \( m=0 \) (\emph{critical point}).
\end{itemize}
As said, the condition \( \beta_c \hat{J} z = 1  \), define the critical point. The critical temperature \( T_c \) is given by
\begin{equation}
  \frac{z \hat{J} }{k_B T_c} = 1 \Rightarrow T_c = \frac{z \hat{J} }{k_B} \neq 0!
\end{equation}
\begin{remark}
\( T_c \) depends on \emph{z} and hence on \emph{D}!
\end{remark}

\subsection{Free-energy expansion for \( m \simeq 0 \)}
The critical point is characterized by the order parameter that is zero. Now we want to expand the free energy around the critical point. Let us put \( H=0 \):
\begin{equation}
  f(m,0,T,\hat{J} ) = \frac{1}{2}\hat{J}zm^2 -k_BT \ln{\qty[\cosh(\beta \hat{J}zm )]}
\end{equation}
Define \( x \equiv \beta \hat{J} z m \simeq 0  \), hence
\begin{equation}
  \cosh (x) \simeq 1 + \underbrace{\frac{x^2}{2} + \frac{x^4}{4!}}_{t \simeq 0}  + \dots
\end{equation}
\begin{equation}
  \log{(1+t)} \simeq t - \frac{1}{2}t^2
\end{equation}
\begin{equation}
  \log{(\cosh x)} \simeq \frac{x^2}{2} + \frac{x^4}{4!} - \frac{1}{2} \frac{x^4}{4}+O(x^6)
  = \frac{x^2}{2} - \frac{x^4}{12}+O(x^6)
\end{equation}
This gives
\begin{equation}
  f(m,0,T,\hat{J} ) \simeq  const + \frac{A}{2} m^2 + \frac{B}{4} m^4 + O (m^6)
\end{equation}
with
\begin{subequations}
\begin{align}
   A & \equiv  \hat{J} z \qty(1- \beta \hat{J} z) \\
    B & \equiv  \beta ^2 \frac{(\hat{J}z )^4}{3} > 0
\end{align}
\end{subequations}

Let us consider:
\begin{itemize}
\item case \( \beta \hat{J} z > 1 \Rightarrow A<0 \): two stable symmetric minima at \( m= \pm m_0 \). Coexistence between the two ordered phases.
\begin{figure}[h!]
\centering
\includegraphics[width=0.4\textwidth]{../lessons/11_image/2.pdf}
\caption{\label{fig:11_2} Plot of the free energy: case \( \beta \hat{J} z > 1 \Rightarrow A<0 \).}
\end{figure}
\item case \( \beta \hat{J} z < 1 \Rightarrow A>0 \): one minimum at \( m=0 \).
\begin{figure}[h!]
\centering
\includegraphics[width=0.4\textwidth]{../lessons/11_image/3.pdf}
\caption{\label{fig:11_3} Plot of the free energy: case \( \beta \hat{J} z < 1 \Rightarrow A>0 \).}
\end{figure}
\item case \( \beta \hat{J} z = 1 \Rightarrow A=0 \): 3 minima coincide at \( m=0 \).

\begin{figure}[h!]
\centering
\includegraphics[width=0.4\textwidth]{../lessons/11_image/4.pdf}
\caption{\label{fig:11_4} Plot of the free energy: case \( \beta \hat{J} z = 1 \Rightarrow A=0 \).}
\end{figure}
\end{itemize}




\end{document}
